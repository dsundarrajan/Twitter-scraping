{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzoFKzSB0stl5DLS4flJXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsundarrajan/Twitter-scraping/blob/main/Twitter_scrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Twitter scraping**\n"
      ],
      "metadata": {
        "id": "dtRjZzS2tu5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages\n",
        "#!pip install snscrape\n",
        "#!pip install pymongo\n",
        "#!pip install streamlit\n",
        "\n",
        "# Import the required packages\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "import datetime\n",
        "import json\n",
        "import streamlit as st\n",
        "\n",
        "#Application Programming Interface (API)\n",
        "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
        "mydb = myclient[\"twitter_scraping_db\"]\n",
        "\n",
        "# Streamlit Graphical User Interface (GUI) \n",
        "\n",
        "#st.subheader(\"\"\"Twitter Data scrap page\"\"\")\n",
        "#with st.form(key='Twitter form'):\n",
        "    \n",
        "    #Search_term=st.text_input('Search here')\n",
        "    #Start_date = st.date_input(\"From date\",datetime.datetime.now())\n",
        "    #End_date = st.date_input(\"To date\",datetime.datetime.now())\n",
        "    #limit = st.slider('Tweet Range',0,1000,step=50)\n",
        "    #output_csv=st.radio('Download the file',['yes','No'])\n",
        "    #file_name=st.text_input('Name the file:',max_chars=25)\n",
        "    #submit_button =st.form_submit_button(label='Search')\n",
        "\n",
        "\n",
        "# Search here ( #anything / Limits)\n",
        "x = str(input('Enter the #tag word you want to search: '))\n",
        "date_entry = input('Enter a date in YYYY-MM-DD format: ')\n",
        "year, month, day = map(int, date_entry.split('-'))\n",
        "date1 = datetime.date(year, month, day)\n",
        "limit_days = int(input('Enter the number of days to limit: '))\n",
        "tweet_limit = int(input('Enter the tweet limit: '))\n",
        "\n",
        "end_date = date1\n",
        "start_date = end_date - datetime.timedelta(limit_days)\n",
        "\n",
        "tweet_list = []\n",
        "tweet_list.clear()\n",
        "\n",
        "#Collecting the twitter data\n",
        "def keyword():\n",
        "    \n",
        "    query = '{} since:{} until:{}'.format(x, start_date, end_date)\n",
        "    print(query)\n",
        "    \n",
        "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper('{}'.format(query)).get_items()):\n",
        "        \n",
        "        if i > tweet_limit:\n",
        "            break\n",
        "            \n",
        "        tweet_list.append({\n",
        "            'Keyword': '{}'.format(x),\n",
        "            'Tweet_Date' : tweet.date, \n",
        "            'Id': tweet.id, \n",
        "            'URL': tweet.url,\n",
        "            'content': tweet.content,\n",
        "            'username': tweet.user.username,\n",
        "            'reply_count': tweet.replyCount,\n",
        "            'retweet_count': tweet.retweetCount,\n",
        "            'like_count': tweet.likeCount})\n",
        "        \n",
        "keyword()\n",
        "df = pd.DataFrame(tweet_list)\n",
        "df.to_csv('{}.csv'.format(x))\n",
        "\n",
        "collection_1 = mydb['Collection_1']\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "Uv2C84qqt03-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}